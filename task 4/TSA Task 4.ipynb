{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e51f64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# Download NLTK data (if not already downloaded)\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9172c05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d772835",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"training.1600000.processed.noemoticon.csv\", encoding=\"latin-1\")\n",
    "df = df.iloc[0:15000,:]\n",
    "df.to_csv(\"text_training_data.csv\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d475ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Load the dataset\n",
    "# Replace 'your_dataset.csv' with the actual path to your dataset file\n",
    "# The dataset should have columns: polarity, id, date, query, user, and text\n",
    "# 0 = negative, 2 = neutral, 4 = positive\n",
    "dataset_path = \"text_training_data.csv\"\n",
    "df = pd.read_csv(dataset_path, encoding=\"latin-1\", names=[\"polarity\", \"id\", \"date\", \"query\", \"user\", \"text\"])\n",
    "\n",
    "# Drop unnecessary columns\n",
    "df = df[[\"polarity\", \"text\"]]\n",
    "\n",
    "# Shuffle the dataset\n",
    "df = df.sample(frac=1, random_state=42)\n",
    "\n",
    "# Define a function to preprocess the text\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Tokenize the text\n",
    "    words = word_tokenize(text)\n",
    "    # Remove stopwords and convert to lowercase\n",
    "    filtered_words = [word.lower() for word in words if word.isalnum() and word.lower() not in stop_words]\n",
    "    return \" \".join(filtered_words)\n",
    "\n",
    "# Preprocess the dataset\n",
    "df[\"text\"] = df[\"text\"].apply(preprocess_text)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X = df[\"text\"].tolist()\n",
    "y = df[\"polarity\"].tolist()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create TF-IDF vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "\n",
    "# Transform text data into TF-IDF features\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416d7bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train a Support Vector Machine (SVM) classifier\n",
    "svm_classifier = SVC(kernel=\"linear\")\n",
    "svm_classifier.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict sentiment labels for the test set\n",
    "y_pred = svm_classifier.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(\"Classification Report:\\n\", classification_rep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ed93ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import sklearn.metrics as sm\n",
    "from sklearn.utils import all_estimators\n",
    "import pickle\n",
    "estimators = all_estimators(type_filter='classifier')\n",
    "model_name=[]\n",
    "model_precision=[]\n",
    "model_accuracy=[]\n",
    "model_training_time=[]\n",
    "classification_rep = []\n",
    "model_path = \"Text.model.save\"\n",
    "for name, get_model in estimators:\n",
    "    try:\n",
    "        model = get_model()\n",
    "        # Train the classifier and measure time\n",
    "        start_time = time.time()\n",
    "        model.fit(X_train_tfidf,y_train)\n",
    "        y_pred=model.predict(X_test_tfidf)\n",
    "        end_time = time.time()\n",
    "        classification_rep.append(classification_report(y_test, y_pred))\n",
    "        model_precision.append(sm.precision_score(y_test, y_pred))\n",
    "        model_accuracy.append(sm.accuracy_score(y_test, y_pred))\n",
    "        model_name.append(name)\n",
    "        model_training_time.append(end_time - start_time)\n",
    "        # Save model with pickle model\n",
    "        with open(model_path + f\"/{name}.pkl\",'wb') as model_file:\n",
    "            pickle.dump(model, model_file)\n",
    "    except Exception as e:\n",
    "        print('Unable to import', name)\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b3cc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results=pd.DataFrame({\"Model Name\":model_name, \"Model accuracy\":model_accuracy, \"Model training time\":model_training_time , \"Model precision\":model_precision})\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17104de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
