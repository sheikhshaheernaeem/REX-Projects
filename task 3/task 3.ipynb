{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3a119f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import tensorflow\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5a3403b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'Training'\n",
    "valid_path = 'Validation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb58fb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define image dimensions and batch size\n",
    "batch_size = 32\n",
    "image_size = (224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee8a0185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 37009 images belonging to 2 classes.\n",
      "Found 11649 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Create data generators with data augmentation for training and validation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255.0,    # Normalize pixel values to [0, 1]\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "valid_datagen = ImageDataGenerator(rescale=1.0/255.0)   # Only rescale for validation data\n",
    "\n",
    "# Create data generators\n",
    "train_data = train_datagen.flow_from_directory(train_path, target_size=image_size, batch_size=batch_size, class_mode='categorical')\n",
    "valid_data = valid_datagen.flow_from_directory(valid_path, target_size=image_size, batch_size=batch_size, class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4e4844a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(2, activation='softmax')  # Output layer with '2' neurons for categorical classification\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31c89061",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.0001), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8d2a2cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1157/1157 [==============================] - 4082s 4s/step - loss: 0.5424 - accuracy: 0.7286 - val_loss: 0.3701 - val_accuracy: 0.8503\n",
      "Epoch 2/3\n",
      "1157/1157 [==============================] - 3992s 3s/step - loss: 0.4511 - accuracy: 0.7975 - val_loss: 0.3118 - val_accuracy: 0.8731\n",
      "Epoch 3/3\n",
      "1157/1157 [==============================] - 4724s 4s/step - loss: 0.3927 - accuracy: 0.8318 - val_loss: 0.2542 - val_accuracy: 0.8972\n"
     ]
    }
   ],
   "source": [
    " history = model.fit(train_data, epochs=3, validation_data=valid_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55f5387d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "365/365 [==============================] - 315s 861ms/step - loss: 0.2542 - accuracy: 0.8972\n",
      "Validation Loss: 0.2541828453540802\n",
      "Validation Accuracy: 0.8971585631370544\n"
     ]
    }
   ],
   "source": [
    "valid_loss, valid_accuracy = model.evaluate(valid_data)\n",
    "print(f'Validation Loss: {valid_loss}')\n",
    "print(f'Validation Accuracy: {valid_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960234d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
